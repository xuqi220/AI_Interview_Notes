1. **Prefix LM 和 Causal LM 区别是什么？**
    
    Prefix LM（前缀语言模型）和Causal LM（因果语言模型）是两种不同类型的语言模型，它们的区别在于生成文本的方式和训练目标。
    
    **Prefix LM**可以看作是Encoder-Decoder模型的变体，前缀中的任意Token间是互相可见的，采用Auto Encoding (AE-自编码)模式。待生成的Token采用的是Auto Regressive (AR-自回归)模式，待生成的Token只能看到前缀中的Tokens。具体例子可以参考ChatGLM系列。
 
    **Causal LM** 是因果语言模型，采用了Transfomer的Decoder，采用Auto Regressive模式，就是根据t时刻之前的token来预测下t时刻的token，主要通过attention_mask实现，目前流行地大多数模型都是这种结构。代表模型有GPT系列、Qwen系列、LLama系列。

2. **大模型LLM的训练目标**

    语言模型通常用来计算文本序列的概率，大语言模型通过大量的语料，采用极大似然估计（Maximum Likelihood Estimation，MLE）估计模型参数。具体来说，大语言模型的训练任务是给定t时刻之前的tokens预测t时刻token，并最大化在语料库中出现的文本序列的概率。

3. **大模型架构**
    Transformer 模型一开始是用来做 seq2seq 任务的，所以它包含 Encoder 和 Decoder 两个部分；他们两者的区别主要是，Encoder 在抽取序列中某一个词的特征时能够看到整个序列中所有的信息，即上文和下文同时看到；而 Decoder 中因为有 mask 机制的存在，使得它在编码某一个词的特征时只能看到自身和它之前的文本信息。

    几种主要的架构:

    以BERT为代表的encoder-only
    以T5和BART为代表的encoder-decoder
    以GPT为代表的decoder-only，
    以UNILM、ChatGLM为代表的PrefixLM(前缀部分是双向，后面将要生成的部分是单向的)

4. **涌现能力是什么？原因？**

    涌现能力（Emergent Ability）是指模型在训练过程中能够生成出令人惊喜、创造性和新颖的内容或行为。这种能力使得模型能够超出其训练数据所提供的内容，并产生出具有创造性和独特性的输出。比如，大模型的规模跨过某个临界值时，模型在某些任务比如数学推理、符号推理等任务上的表现大幅提升。典型的相关研究就是few-shot能力、COT等。

5. **为何现在的大模型大部分是Decoder only结构**
* **效率**：decoder-only支持一直复用KV-Cache，对多轮对话更友好，每个Token的表示之和它之前的输入有关，有利于token表示复用，而encoder-decoder和PrefixLM，需要考虑新生成的token，因此难以做到。
* **经验**：就生成任务而言，引入双向注意力并无实质好处。有可能损害模型的创造性。

6. **什么是LLMs复读机问题？什么原因造成的？如何缓解？**
   
   **训练阶段**：增加文本的多样性，去掉重复的文本；
   
   **推理阶段**：调整温度参数，较高的温度值会增加随机性，从而减少复读机问题的出现；Beam search 参数调整,增加搜索的广度；Post Edit 人工干预，去掉重复文本。


7. **LLMs输入句子长度理论上可以无限长吗？**
   
   理论上来说，LLMs（大型语言模型）可以处理任意长度的输入句子，但实际上存在一些限制和挑战。
   
   **计算资源**：更长的上下文，意味着在训练和推理过程中需要更多的计算资源（时间、空间复杂度）

   **建模能力**：更长的上下文可能有更加复杂的语义，需要模型具有更强的建模能力

8.  **如何让大模型处理更长的文本？**
    **优化模型结构**：例如增加模型的层，提升模型的语言建模能力；优化归一化层（例如，LayerNorm->RMSNorm去中心化）提升计算效率等。
    **分块处理**：将文档分块处理，但是会损失一部分语义。

9. **大模型的适用场景**
    
    需要从应用场景、可用计算资源等多个维度考虑，如：
    
    **BERT**：适用于各种自然语言理解任务，比如：文本分类、情感识别、命名实体识别等。

    **LLaMA**：在常识推理、问答、数学推理、代码生成、语言理解任务上表现较好。训练预料主要为以英语为主的拉丁语系，不包含中日韩文。所以适合于英文文本生成的任务。
