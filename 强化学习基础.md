# 马尔可夫决策过程
马尔可夫决策过程（Markov decision process，MDP）是强化学习的重要概念。如果要用强化学习去解决一个实际问题，第一步要做的事情就是把这个实际问题抽象为一个马尔可夫决策过程，也就是明确马尔可夫决策过程的各个组成要素。本节将从马尔可夫过程、马尔可夫奖励过程引出马尔可夫决策过程。

## 马尔可夫过程
### 随机过程
**随机过程**（stochastic process）是概率论的“动力学”部分。概率论的研究对象是静态的随机现象，而随机过程的研究对象是随时间演变的随机现象（例如天气随时间的变化、城市交通随时间的变化）。在随机过程中，随机现象在某时刻 $t$ 的取值是一个向量随机变量，用 $S_{t}$ 表示，所有可能的状态组成状态集合 $S$ 。随机现象便是状态的变化过程。在某时刻 $t$ 的状态通常取决于时刻 $t$ 之前的状态。我们将已知历史信息 $(S_1, S_2,...,S_t)$ 的下一个时刻状态 $S_{t+1}$ 的概率表示成 $P(S_{t+1}|S_{1}, S_2,...,S_t)$ 。

### 马尔可夫性质
且仅当某时刻的状态只取决于上一时刻的状态时，一个随机过程被称为具有**马尔可夫性质**（Markov property），用公式表示为 $P(S_{t+1}|S_{1}, S_2,...,S_t)=P(S_{t+1}|S_t)$ 。也就是说，当前状态是未来的充分统计量，即下一个状态只取决于当前状态，而不会受到过去状态的影响。需要明确的是，具有马尔可夫性并不代表这个随机过程就和历史完全没有关系。因为虽然时刻 $t+1$ 的状态只与 $t$ 时刻的状态有关，但是 $t$ 时刻的状态其实包含了 $t-1$ 时刻的状态的信息，通过这种链式的关系，历史的信息被传递到了现在。马尔可夫性可以大大简化运算，因为只要当前状态可知，所有的历史信息都不再需要了，利用当前状态信息就可以决定未来。

### 马尔可夫过程
**马尔可夫过程**（Markov process）指具有马尔可夫性质的随机过程，也被称为**马尔可夫链**（Markov chain）。马尔可夫过程有两个要素：$<\mathcal{S}, \mathcal{P}>$ 。其中，$\mathcal{S}$ 表示有限状态集合 ${S_1, S_2,...,S_n}$，




